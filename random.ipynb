{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "pip install scikit-learn imbalanced-learn"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C98CFJVWm8Gi",
        "outputId": "3d81502c-d923-403e-cbdf-c75d40efff45"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.3.2)\n",
            "Requirement already satisfied: imbalanced-learn in /usr/local/lib/python3.10/dist-packages (0.12.3)\n",
            "Requirement already satisfied: numpy<2.0,>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.5.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from imblearn.pipeline import Pipeline\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Example data creation (replace this with your actual data loading)\n",
        "np.random.seed(42)  # For reproducibility\n",
        "data = {\n",
        "    'vegetable_oils_and_resins': np.random.uniform(0, 50, 1000),\n",
        "    'methane_and_ethane': np.random.uniform(0, 20, 1000),\n",
        "    'white_phosphorus': np.random.uniform(0, 2, 1000),\n",
        "    'sulfur': np.random.uniform(0, 10, 1000),\n",
        "    'animal_fats': np.random.uniform(0, 40, 1000),\n",
        "\n",
        "    'human_chemicals': np.random.uniform(0, 5, 1000),\n",
        "    'nitrogenous_compounds': np.random.uniform(0, 30, 1000),\n",
        "    'alert': np.random.choice([0, 1], size=1000, p=[0.1, 0.9])  # Imbalanced target\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "X = df.drop('alert', axis=1)\n",
        "y = df['alert']\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Define the model with class weights\n",
        "rf = RandomForestClassifier(random_state=42)\n",
        "\n",
        "# Define the pipeline with scaling, SMOTE, and classifier\n",
        "pipeline = Pipeline([\n",
        "    ('scaler', StandardScaler()),  # Standardize features\n",
        "    ('smote', SMOTE(random_state=42)),  # Balance classes\n",
        "    ('classifier', rf)  # Random Forest classifier\n",
        "])\n",
        "\n",
        "# Grid search for hyperparameter tuning\n",
        "param_grid = {\n",
        "    'classifier__n_estimators': [100, 200],\n",
        "    'classifier__max_depth': [10, 20, None],\n",
        "    'classifier__class_weight': [None, 'balanced']\n",
        "}\n",
        "\n",
        "grid_search = GridSearchCV(pipeline, param_grid, cv=3, scoring='accuracy', n_jobs=-1, verbose=2)\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred = grid_search.predict(X_test)\n",
        "\n",
        "# Print classification report and accuracy\n",
        "print(\"Classification Report:\\n\", classification_report(y_test, y_pred, zero_division=1))\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "\n",
        "# Check if risk level is high and output a message\n",
        "high_risk_proportion = np.mean(y_pred)  # Proportion of predictions classified as high risk (class 1)\n",
        "threshold = 0.5  # Define a threshold to consider the risk level high\n",
        "\n",
        "if high_risk_proportion > threshold:\n",
        "    print(f\"Alert: High risk level detected! Proportion of high-risk predictions: {high_risk_proportion:.2f}\")\n",
        "else:\n",
        "    print(f\"Risk level is normal. Proportion of high-risk predictions: {high_risk_proportion:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9scZtdHenEg9",
        "outputId": "1ee30a35-1249-421e-acc2-05dda0b9e0fa"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 3 folds for each of 12 candidates, totalling 36 fits\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.14      0.15      0.14        33\n",
            "           1       0.89      0.88      0.89       267\n",
            "\n",
            "    accuracy                           0.80       300\n",
            "   macro avg       0.52      0.52      0.52       300\n",
            "weighted avg       0.81      0.80      0.81       300\n",
            "\n",
            "Accuracy: 0.8033333333333333\n",
            "Alert: High risk level detected! Proportion of high-risk predictions: 0.88\n"
          ]
        }
      ]
    }
  ]
}